{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e93102f3-abee-4d91-937e-df56a30b3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Extract CSV zip files\n",
    "if not os.path.isfile('mhealth_raw_data.csv'):\n",
    "    with zipfile.ZipFile('archive.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "\n",
    "m_health_raw_data = pd.read_csv('mhealth_raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d002b62b-610c-46f0-a120-4a5d64a1138b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alx</th>\n",
       "      <th>aly</th>\n",
       "      <th>alz</th>\n",
       "      <th>glx</th>\n",
       "      <th>gly</th>\n",
       "      <th>glz</th>\n",
       "      <th>arx</th>\n",
       "      <th>ary</th>\n",
       "      <th>arz</th>\n",
       "      <th>grx</th>\n",
       "      <th>gry</th>\n",
       "      <th>grz</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1212350</th>\n",
       "      <td>1.33590</td>\n",
       "      <td>-9.7394</td>\n",
       "      <td>-1.66110</td>\n",
       "      <td>0.58813</td>\n",
       "      <td>-0.58724</td>\n",
       "      <td>-0.662080</td>\n",
       "      <td>-3.2703</td>\n",
       "      <td>-9.05310</td>\n",
       "      <td>-0.30682</td>\n",
       "      <td>0.401960</td>\n",
       "      <td>-1.06160</td>\n",
       "      <td>0.14655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134482</th>\n",
       "      <td>2.52730</td>\n",
       "      <td>-12.7320</td>\n",
       "      <td>-3.88220</td>\n",
       "      <td>0.51763</td>\n",
       "      <td>-0.58537</td>\n",
       "      <td>-0.758350</td>\n",
       "      <td>-4.3463</td>\n",
       "      <td>-10.51300</td>\n",
       "      <td>1.71390</td>\n",
       "      <td>-0.272550</td>\n",
       "      <td>-0.76591</td>\n",
       "      <td>0.85129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820343</th>\n",
       "      <td>0.55205</td>\n",
       "      <td>-9.7466</td>\n",
       "      <td>1.58070</td>\n",
       "      <td>0.55288</td>\n",
       "      <td>-0.76173</td>\n",
       "      <td>-0.176820</td>\n",
       "      <td>-5.8155</td>\n",
       "      <td>-8.16430</td>\n",
       "      <td>-2.42900</td>\n",
       "      <td>0.137250</td>\n",
       "      <td>-0.99795</td>\n",
       "      <td>0.52155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718210</th>\n",
       "      <td>2.49960</td>\n",
       "      <td>-9.3680</td>\n",
       "      <td>1.81700</td>\n",
       "      <td>0.73655</td>\n",
       "      <td>-0.55159</td>\n",
       "      <td>0.068762</td>\n",
       "      <td>-3.0504</td>\n",
       "      <td>-5.91350</td>\n",
       "      <td>4.65220</td>\n",
       "      <td>0.084314</td>\n",
       "      <td>-0.71047</td>\n",
       "      <td>0.90086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118798</th>\n",
       "      <td>-3.48370</td>\n",
       "      <td>-9.2520</td>\n",
       "      <td>0.54423</td>\n",
       "      <td>-0.37662</td>\n",
       "      <td>-0.61163</td>\n",
       "      <td>0.609040</td>\n",
       "      <td>-6.5952</td>\n",
       "      <td>-0.79894</td>\n",
       "      <td>7.10590</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>1.14580</td>\n",
       "      <td>0.81897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             alx      aly      alz      glx      gly       glz     arx  \\\n",
       "1212350  1.33590  -9.7394 -1.66110  0.58813 -0.58724 -0.662080 -3.2703   \n",
       "134482   2.52730 -12.7320 -3.88220  0.51763 -0.58537 -0.758350 -4.3463   \n",
       "820343   0.55205  -9.7466  1.58070  0.55288 -0.76173 -0.176820 -5.8155   \n",
       "718210   2.49960  -9.3680  1.81700  0.73655 -0.55159  0.068762 -3.0504   \n",
       "118798  -3.48370  -9.2520  0.54423 -0.37662 -0.61163  0.609040 -6.5952   \n",
       "\n",
       "              ary      arz       grx      gry      grz  Activity  \n",
       "1212350  -9.05310 -0.30682  0.401960 -1.06160  0.14655         0  \n",
       "134482  -10.51300  1.71390 -0.272550 -0.76591  0.85129         0  \n",
       "820343   -8.16430 -2.42900  0.137250 -0.99795  0.52155         0  \n",
       "718210   -5.91350  4.65220  0.084314 -0.71047  0.90086         0  \n",
       "118798   -0.79894  7.10590 -0.900000  1.14580  0.81897         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's sample 10000 entries for each category\n",
    "# Drop the subject column\n",
    "m_health_data = m_health_raw_data.drop('subject', axis=1)\n",
    "seed=42\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in m_health_data['Activity'].unique():\n",
    "    samples = m_health_data[m_health_data['Activity'] == i].sample(random_state=seed, n=10000)\n",
    "    df = pd.concat([df, samples])\n",
    "\n",
    "ms = df.copy()\n",
    "display(ms.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dabfbff-50fa-4ac9-bafb-bbfe383f4c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['alx', 'aly', 'alz', 'glx', 'gly', 'glz', 'arx', 'ary', 'arz', 'grx',\n",
       "       'gry', 'grz', 'Activity', 'Magnitude Left Acc', 'Magnitude Right Acc'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alx</th>\n",
       "      <th>aly</th>\n",
       "      <th>alz</th>\n",
       "      <th>glx</th>\n",
       "      <th>gly</th>\n",
       "      <th>glz</th>\n",
       "      <th>arx</th>\n",
       "      <th>ary</th>\n",
       "      <th>arz</th>\n",
       "      <th>grx</th>\n",
       "      <th>gry</th>\n",
       "      <th>grz</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Magnitude Left Acc</th>\n",
       "      <th>Magnitude Right Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.00000</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.712190</td>\n",
       "      <td>-9.092605</td>\n",
       "      <td>-0.833864</td>\n",
       "      <td>0.081737</td>\n",
       "      <td>-0.56323</td>\n",
       "      <td>-0.137402</td>\n",
       "      <td>-3.520445</td>\n",
       "      <td>-5.656282</td>\n",
       "      <td>2.318159</td>\n",
       "      <td>-0.228825</td>\n",
       "      <td>-0.416495</td>\n",
       "      <td>0.358143</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.194571</td>\n",
       "      <td>11.088392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.431388</td>\n",
       "      <td>5.286531</td>\n",
       "      <td>6.568060</td>\n",
       "      <td>0.467020</td>\n",
       "      <td>0.41718</td>\n",
       "      <td>0.554810</td>\n",
       "      <td>6.041450</td>\n",
       "      <td>6.593481</td>\n",
       "      <td>4.251687</td>\n",
       "      <td>0.543354</td>\n",
       "      <td>0.544666</td>\n",
       "      <td>0.528319</td>\n",
       "      <td>3.741672</td>\n",
       "      <td>5.321501</td>\n",
       "      <td>4.985766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-22.146000</td>\n",
       "      <td>-19.609000</td>\n",
       "      <td>-19.365000</td>\n",
       "      <td>-1.777400</td>\n",
       "      <td>-7.78990</td>\n",
       "      <td>-2.622800</td>\n",
       "      <td>-22.345000</td>\n",
       "      <td>-18.972000</td>\n",
       "      <td>-18.230000</td>\n",
       "      <td>-2.219600</td>\n",
       "      <td>-3.552400</td>\n",
       "      <td>-2.504300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.537706</td>\n",
       "      <td>0.144361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082362</td>\n",
       "      <td>-10.137000</td>\n",
       "      <td>-3.664900</td>\n",
       "      <td>-0.374770</td>\n",
       "      <td>-0.81051</td>\n",
       "      <td>-0.591360</td>\n",
       "      <td>-5.221425</td>\n",
       "      <td>-9.535500</td>\n",
       "      <td>0.051838</td>\n",
       "      <td>-0.696080</td>\n",
       "      <td>-0.839840</td>\n",
       "      <td>-0.077586</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.752254</td>\n",
       "      <td>8.997784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.332000</td>\n",
       "      <td>-9.601300</td>\n",
       "      <td>0.261925</td>\n",
       "      <td>0.172540</td>\n",
       "      <td>-0.69043</td>\n",
       "      <td>-0.123770</td>\n",
       "      <td>-2.504100</td>\n",
       "      <td>-7.562000</td>\n",
       "      <td>1.776100</td>\n",
       "      <td>-0.333330</td>\n",
       "      <td>-0.597540</td>\n",
       "      <td>0.424570</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.949205</td>\n",
       "      <td>9.794379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.892000</td>\n",
       "      <td>-7.492100</td>\n",
       "      <td>1.771100</td>\n",
       "      <td>0.484230</td>\n",
       "      <td>-0.49719</td>\n",
       "      <td>0.345780</td>\n",
       "      <td>-0.517068</td>\n",
       "      <td>-1.843100</td>\n",
       "      <td>5.181400</td>\n",
       "      <td>0.205880</td>\n",
       "      <td>-0.051335</td>\n",
       "      <td>0.829740</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.261475</td>\n",
       "      <td>11.498591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.033000</td>\n",
       "      <td>21.161000</td>\n",
       "      <td>25.005000</td>\n",
       "      <td>1.705000</td>\n",
       "      <td>1.97750</td>\n",
       "      <td>1.799600</td>\n",
       "      <td>19.801000</td>\n",
       "      <td>21.965000</td>\n",
       "      <td>25.741000</td>\n",
       "      <td>1.429400</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>2.254300</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>38.929267</td>\n",
       "      <td>40.500573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 alx            aly            alz            glx  \\\n",
       "count  130000.000000  130000.000000  130000.000000  130000.000000   \n",
       "mean        1.712190      -9.092605      -0.833864       0.081737   \n",
       "std         4.431388       5.286531       6.568060       0.467020   \n",
       "min       -22.146000     -19.609000     -19.365000      -1.777400   \n",
       "25%         0.082362     -10.137000      -3.664900      -0.374770   \n",
       "50%         1.332000      -9.601300       0.261925       0.172540   \n",
       "75%         2.892000      -7.492100       1.771100       0.484230   \n",
       "max        20.033000      21.161000      25.005000       1.705000   \n",
       "\n",
       "                gly            glz            arx            ary  \\\n",
       "count  130000.00000  130000.000000  130000.000000  130000.000000   \n",
       "mean       -0.56323      -0.137402      -3.520445      -5.656282   \n",
       "std         0.41718       0.554810       6.041450       6.593481   \n",
       "min        -7.78990      -2.622800     -22.345000     -18.972000   \n",
       "25%        -0.81051      -0.591360      -5.221425      -9.535500   \n",
       "50%        -0.69043      -0.123770      -2.504100      -7.562000   \n",
       "75%        -0.49719       0.345780      -0.517068      -1.843100   \n",
       "max         1.97750       1.799600      19.801000      21.965000   \n",
       "\n",
       "                 arz            grx            gry            grz  \\\n",
       "count  130000.000000  130000.000000  130000.000000  130000.000000   \n",
       "mean        2.318159      -0.228825      -0.416495       0.358143   \n",
       "std         4.251687       0.543354       0.544666       0.528319   \n",
       "min       -18.230000      -2.219600      -3.552400      -2.504300   \n",
       "25%         0.051838      -0.696080      -0.839840      -0.077586   \n",
       "50%         1.776100      -0.333330      -0.597540       0.424570   \n",
       "75%         5.181400       0.205880      -0.051335       0.829740   \n",
       "max        25.741000       1.429400       1.540000       2.254300   \n",
       "\n",
       "            Activity  Magnitude Left Acc  Magnitude Right Acc  \n",
       "count  130000.000000       130000.000000        130000.000000  \n",
       "mean        6.000000           12.194571            11.088392  \n",
       "std         3.741672            5.321501             4.985766  \n",
       "min         0.000000            0.537706             0.144361  \n",
       "25%         3.000000            9.752254             8.997784  \n",
       "50%         6.000000            9.949205             9.794379  \n",
       "75%         9.000000           12.261475            11.498591  \n",
       "max        12.000000           38.929267            40.500573  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature expansion magnitude of acceleration\n",
    "ms['Magnitude Left Acc'] = np.sqrt(ms['alx']**2 + ms['aly']**2 + ms['alz']**2)\n",
    "ms['Magnitude Right Acc'] = np.sqrt(ms['arx']**2 + ms['ary']**2 + ms['arz']**2)\n",
    "display(ms.columns)\n",
    "display(ms.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9bffd46-b348-4f78-bf94-71a80205b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def GenerateReport(model, X_train, X_test, y_train, y_test):\n",
    "    # Checking training error\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    conf_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "    class_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "    # Printing accuracy, precision, and recall\n",
    "    print(\"Train Accuracy:\", accuracy)\n",
    "    print(\"Train Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # Checking testing error\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    class_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    print(\"Test Classification Report:\")\n",
    "    print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec5bf7af-8826-41ff-906e-fb14b1df78c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13762393162393163\n",
      "0.14846153846153845\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ms.drop(['Activity'], axis = 1), ms['Activity'], test_size=0.1, random_state=seed)\n",
    "\n",
    "# Scale the input data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "lin_reg_model = LinearRegression()\n",
    "\n",
    "# Fitting the model to the training data\n",
    "lin_reg_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lin_reg_model.predict(X_train)\n",
    "y_train_pred = y_train_pred.round()\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(accuracy)\n",
    "\n",
    "y_test_pred = lin_reg_model.predict(X_test)\n",
    "y_test_pred = y_test_pred.round()\n",
    "accuracy2 = accuracy_score(y_test, y_test_pred)\n",
    "print(accuracy2)\n",
    "\n",
    "#GenerateReport(lin_reg_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9806f0e9-e4a8-4d78-aba3-9e32721f884a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4be981-2bd5-4e60-83fe-ffaeba05fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Running\")\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(ms.drop(['Activity'], axis = 1), ms['Activity'], test_size=0.1, random_state=seed)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# Initialize and train the model\n",
    "for i in range(5):\n",
    "    print(\"Running\")\n",
    "    k = i * 2 + 11\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Running\")\n",
    "    GenerateReport(knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b92d9733-2218-4782-8464-a26342e90428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running\n",
      "Running\n",
      "Train Accuracy: 0.9257606837606838\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.47      0.62      8975\n",
      "           1       0.96      1.00      0.98      8993\n",
      "           2       0.98      1.00      0.99      8985\n",
      "           3       0.98      1.00      0.99      8985\n",
      "           4       0.84      0.99      0.91      9008\n",
      "           5       0.93      0.87      0.90      9028\n",
      "           6       0.92      0.99      0.95      9009\n",
      "           7       0.92      0.99      0.95      8942\n",
      "           8       0.90      0.99      0.94      9006\n",
      "           9       0.95      1.00      0.97      9020\n",
      "          10       0.88      0.94      0.91      9011\n",
      "          11       0.91      0.94      0.92      9051\n",
      "          12       0.95      0.86      0.90      8987\n",
      "\n",
      "    accuracy                           0.93    117000\n",
      "   macro avg       0.93      0.93      0.92    117000\n",
      "weighted avg       0.93      0.93      0.92    117000\n",
      "\n",
      "Test Accuracy: 0.6079230769230769\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.45      0.30      1025\n",
      "           1       0.89      0.14      0.24      1007\n",
      "           2       0.93      0.21      0.34      1015\n",
      "           3       0.99      1.00      0.99      1015\n",
      "           4       0.75      0.48      0.59       992\n",
      "           5       0.24      0.65      0.35       972\n",
      "           6       0.60      0.37      0.46       991\n",
      "           7       0.66      0.80      0.72      1058\n",
      "           8       0.72      0.36      0.48       994\n",
      "           9       0.83      0.86      0.84       980\n",
      "          10       0.82      0.88      0.85       989\n",
      "          11       0.89      0.86      0.88       949\n",
      "          12       0.92      0.86      0.89      1013\n",
      "\n",
      "    accuracy                           0.61     13000\n",
      "   macro avg       0.73      0.61      0.61     13000\n",
      "weighted avg       0.73      0.61      0.61     13000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Running\")\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(ms.drop(['Activity'], axis = 1), ms['Activity'], test_size=0.1, random_state=seed)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "k = 19\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Running\")\n",
    "GenerateReport(knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f6b730d-6eb6-4264-afbe-0e9c89151c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alx</th>\n",
       "      <th>aly</th>\n",
       "      <th>alz</th>\n",
       "      <th>glx</th>\n",
       "      <th>gly</th>\n",
       "      <th>glz</th>\n",
       "      <th>arx</th>\n",
       "      <th>ary</th>\n",
       "      <th>arz</th>\n",
       "      <th>grx</th>\n",
       "      <th>gry</th>\n",
       "      <th>grz</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1212350</th>\n",
       "      <td>1.33590</td>\n",
       "      <td>-9.7394</td>\n",
       "      <td>-1.66110</td>\n",
       "      <td>0.58813</td>\n",
       "      <td>-0.58724</td>\n",
       "      <td>-0.662080</td>\n",
       "      <td>-3.2703</td>\n",
       "      <td>-9.05310</td>\n",
       "      <td>-0.30682</td>\n",
       "      <td>0.401960</td>\n",
       "      <td>-1.06160</td>\n",
       "      <td>0.14655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134482</th>\n",
       "      <td>2.52730</td>\n",
       "      <td>-12.7320</td>\n",
       "      <td>-3.88220</td>\n",
       "      <td>0.51763</td>\n",
       "      <td>-0.58537</td>\n",
       "      <td>-0.758350</td>\n",
       "      <td>-4.3463</td>\n",
       "      <td>-10.51300</td>\n",
       "      <td>1.71390</td>\n",
       "      <td>-0.272550</td>\n",
       "      <td>-0.76591</td>\n",
       "      <td>0.85129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820343</th>\n",
       "      <td>0.55205</td>\n",
       "      <td>-9.7466</td>\n",
       "      <td>1.58070</td>\n",
       "      <td>0.55288</td>\n",
       "      <td>-0.76173</td>\n",
       "      <td>-0.176820</td>\n",
       "      <td>-5.8155</td>\n",
       "      <td>-8.16430</td>\n",
       "      <td>-2.42900</td>\n",
       "      <td>0.137250</td>\n",
       "      <td>-0.99795</td>\n",
       "      <td>0.52155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718210</th>\n",
       "      <td>2.49960</td>\n",
       "      <td>-9.3680</td>\n",
       "      <td>1.81700</td>\n",
       "      <td>0.73655</td>\n",
       "      <td>-0.55159</td>\n",
       "      <td>0.068762</td>\n",
       "      <td>-3.0504</td>\n",
       "      <td>-5.91350</td>\n",
       "      <td>4.65220</td>\n",
       "      <td>0.084314</td>\n",
       "      <td>-0.71047</td>\n",
       "      <td>0.90086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118798</th>\n",
       "      <td>-3.48370</td>\n",
       "      <td>-9.2520</td>\n",
       "      <td>0.54423</td>\n",
       "      <td>-0.37662</td>\n",
       "      <td>-0.61163</td>\n",
       "      <td>0.609040</td>\n",
       "      <td>-6.5952</td>\n",
       "      <td>-0.79894</td>\n",
       "      <td>7.10590</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>1.14580</td>\n",
       "      <td>0.81897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             alx      aly      alz      glx      gly       glz     arx  \\\n",
       "1212350  1.33590  -9.7394 -1.66110  0.58813 -0.58724 -0.662080 -3.2703   \n",
       "134482   2.52730 -12.7320 -3.88220  0.51763 -0.58537 -0.758350 -4.3463   \n",
       "820343   0.55205  -9.7466  1.58070  0.55288 -0.76173 -0.176820 -5.8155   \n",
       "718210   2.49960  -9.3680  1.81700  0.73655 -0.55159  0.068762 -3.0504   \n",
       "118798  -3.48370  -9.2520  0.54423 -0.37662 -0.61163  0.609040 -6.5952   \n",
       "\n",
       "              ary      arz       grx      gry      grz  Activity  \n",
       "1212350  -9.05310 -0.30682  0.401960 -1.06160  0.14655         0  \n",
       "134482  -10.51300  1.71390 -0.272550 -0.76591  0.85129         0  \n",
       "820343   -8.16430 -2.42900  0.137250 -0.99795  0.52155         0  \n",
       "718210   -5.91350  4.65220  0.084314 -0.71047  0.90086         0  \n",
       "118798   -0.79894  7.10590 -0.900000  1.14580  0.81897         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['alx', 'aly', 'alz', 'glx', 'gly', 'glz', 'arx', 'ary', 'arz', 'grx',\n",
       "       'gry', 'grz', 'Activity', 'Magnitude Left Acc', 'Magnitude Right Acc'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alx</th>\n",
       "      <th>aly</th>\n",
       "      <th>alz</th>\n",
       "      <th>glx</th>\n",
       "      <th>gly</th>\n",
       "      <th>glz</th>\n",
       "      <th>arx</th>\n",
       "      <th>ary</th>\n",
       "      <th>arz</th>\n",
       "      <th>grx</th>\n",
       "      <th>gry</th>\n",
       "      <th>grz</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Magnitude Left Acc</th>\n",
       "      <th>Magnitude Right Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.710203</td>\n",
       "      <td>-9.077714</td>\n",
       "      <td>-0.757218</td>\n",
       "      <td>0.080622</td>\n",
       "      <td>-0.564444</td>\n",
       "      <td>-0.139305</td>\n",
       "      <td>-3.462329</td>\n",
       "      <td>-5.540851</td>\n",
       "      <td>2.285552</td>\n",
       "      <td>-0.234437</td>\n",
       "      <td>-0.417676</td>\n",
       "      <td>0.355221</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.201214</td>\n",
       "      <td>10.975043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.492552</td>\n",
       "      <td>5.352048</td>\n",
       "      <td>6.548589</td>\n",
       "      <td>0.467756</td>\n",
       "      <td>0.417393</td>\n",
       "      <td>0.553625</td>\n",
       "      <td>5.956603</td>\n",
       "      <td>6.571494</td>\n",
       "      <td>4.158290</td>\n",
       "      <td>0.543855</td>\n",
       "      <td>0.543898</td>\n",
       "      <td>0.528269</td>\n",
       "      <td>3.741801</td>\n",
       "      <td>5.360974</td>\n",
       "      <td>4.838633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-22.075000</td>\n",
       "      <td>-19.590000</td>\n",
       "      <td>-19.364000</td>\n",
       "      <td>-1.680900</td>\n",
       "      <td>-2.594700</td>\n",
       "      <td>-2.400800</td>\n",
       "      <td>-22.221000</td>\n",
       "      <td>-18.932000</td>\n",
       "      <td>-18.228000</td>\n",
       "      <td>-1.764700</td>\n",
       "      <td>-3.112900</td>\n",
       "      <td>-1.588400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.002524</td>\n",
       "      <td>0.677570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.104772</td>\n",
       "      <td>-10.116500</td>\n",
       "      <td>-3.529450</td>\n",
       "      <td>-0.384040</td>\n",
       "      <td>-0.810510</td>\n",
       "      <td>-0.589390</td>\n",
       "      <td>-5.171950</td>\n",
       "      <td>-9.502000</td>\n",
       "      <td>0.064240</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.835730</td>\n",
       "      <td>-0.075970</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.755693</td>\n",
       "      <td>8.977011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.339550</td>\n",
       "      <td>-9.603200</td>\n",
       "      <td>0.312455</td>\n",
       "      <td>0.176250</td>\n",
       "      <td>-0.692310</td>\n",
       "      <td>-0.127700</td>\n",
       "      <td>-2.500050</td>\n",
       "      <td>-7.519000</td>\n",
       "      <td>1.763700</td>\n",
       "      <td>-0.341180</td>\n",
       "      <td>-0.601640</td>\n",
       "      <td>0.420260</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.945730</td>\n",
       "      <td>9.790397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.890950</td>\n",
       "      <td>-7.470750</td>\n",
       "      <td>1.802375</td>\n",
       "      <td>0.482370</td>\n",
       "      <td>-0.495310</td>\n",
       "      <td>0.342340</td>\n",
       "      <td>-0.522805</td>\n",
       "      <td>-1.690025</td>\n",
       "      <td>5.059125</td>\n",
       "      <td>0.196080</td>\n",
       "      <td>-0.055441</td>\n",
       "      <td>0.827590</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.241402</td>\n",
       "      <td>11.392067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.024000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>24.843000</td>\n",
       "      <td>1.582600</td>\n",
       "      <td>1.684800</td>\n",
       "      <td>1.534400</td>\n",
       "      <td>19.692000</td>\n",
       "      <td>21.924000</td>\n",
       "      <td>24.560000</td>\n",
       "      <td>1.305900</td>\n",
       "      <td>1.205300</td>\n",
       "      <td>1.926700</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>38.906480</td>\n",
       "      <td>38.407873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                alx           aly           alz           glx           gly  \\\n",
       "count  13000.000000  13000.000000  13000.000000  13000.000000  13000.000000   \n",
       "mean       1.710203     -9.077714     -0.757218      0.080622     -0.564444   \n",
       "std        4.492552      5.352048      6.548589      0.467756      0.417393   \n",
       "min      -22.075000    -19.590000    -19.364000     -1.680900     -2.594700   \n",
       "25%        0.104772    -10.116500     -3.529450     -0.384040     -0.810510   \n",
       "50%        1.339550     -9.603200      0.312455      0.176250     -0.692310   \n",
       "75%        2.890950     -7.470750      1.802375      0.482370     -0.495310   \n",
       "max       20.024000     21.000000     24.843000      1.582600      1.684800   \n",
       "\n",
       "                glz           arx           ary           arz           grx  \\\n",
       "count  13000.000000  13000.000000  13000.000000  13000.000000  13000.000000   \n",
       "mean      -0.139305     -3.462329     -5.540851      2.285552     -0.234437   \n",
       "std        0.553625      5.956603      6.571494      4.158290      0.543855   \n",
       "min       -2.400800    -22.221000    -18.932000    -18.228000     -1.764700   \n",
       "25%       -0.589390     -5.171950     -9.502000      0.064240     -0.700000   \n",
       "50%       -0.127700     -2.500050     -7.519000      1.763700     -0.341180   \n",
       "75%        0.342340     -0.522805     -1.690025      5.059125      0.196080   \n",
       "max        1.534400     19.692000     21.924000     24.560000      1.305900   \n",
       "\n",
       "                gry           grz      Activity  Magnitude Left Acc  \\\n",
       "count  13000.000000  13000.000000  13000.000000        13000.000000   \n",
       "mean      -0.417676      0.355221      6.000000           12.201214   \n",
       "std        0.543898      0.528269      3.741801            5.360974   \n",
       "min       -3.112900     -1.588400      0.000000            1.002524   \n",
       "25%       -0.835730     -0.075970      3.000000            9.755693   \n",
       "50%       -0.601640      0.420260      6.000000            9.945730   \n",
       "75%       -0.055441      0.827590      9.000000           12.241402   \n",
       "max        1.205300      1.926700     12.000000           38.906480   \n",
       "\n",
       "       Magnitude Right Acc  \n",
       "count         13000.000000  \n",
       "mean             10.975043  \n",
       "std               4.838633  \n",
       "min               0.677570  \n",
       "25%               8.977011  \n",
       "50%               9.790397  \n",
       "75%              11.392067  \n",
       "max              38.407873  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's sample 1000 entries for each category for the SVM\n",
    "# Drop the subject column\n",
    "m_health_data = m_health_raw_data.drop('subject', axis=1)\n",
    "seed=42\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in m_health_data['Activity'].unique():\n",
    "    samples = m_health_data[m_health_data['Activity'] == i].sample(random_state=seed, n=1000)\n",
    "    df = pd.concat([df, samples])\n",
    "\n",
    "ms = df.copy()\n",
    "display(ms.head())\n",
    "\n",
    "# feature expansion magnitude of acceleration\n",
    "ms['Magnitude Left Acc'] = np.sqrt(ms['alx']**2 + ms['aly']**2 + ms['alz']**2)\n",
    "ms['Magnitude Right Acc'] = np.sqrt(ms['arx']**2 + ms['ary']**2 + ms['arz']**2)\n",
    "display(ms.columns)\n",
    "display(ms.describe())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ms.drop(['Activity'], axis = 1), ms['Activity'], test_size=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "481b7bdf-fdd5-4305-936d-08bb067e2bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Kernel: linear\n",
      "Train Accuracy: 0.7314529914529915\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.21      0.29       891\n",
      "           1       0.75      0.99      0.85       900\n",
      "           2       0.89      1.00      0.94       895\n",
      "           3       0.99      1.00      0.99       898\n",
      "           4       0.61      0.72      0.66       893\n",
      "           5       0.59      0.49      0.53       913\n",
      "           6       0.72      0.81      0.77       896\n",
      "           7       0.89      0.81      0.85       911\n",
      "           8       0.60      0.64      0.62       898\n",
      "           9       0.91      0.95      0.93       885\n",
      "          10       0.65      0.59      0.61       902\n",
      "          11       0.67      0.86      0.76       900\n",
      "          12       0.62      0.46      0.53       918\n",
      "\n",
      "    accuracy                           0.73     11700\n",
      "   macro avg       0.72      0.73      0.72     11700\n",
      "weighted avg       0.72      0.73      0.72     11700\n",
      "\n",
      "Test Accuracy: 0.7476923076923077\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.24      0.33       109\n",
      "           1       0.74      0.98      0.84       100\n",
      "           2       0.86      1.00      0.93       105\n",
      "           3       1.00      1.00      1.00       102\n",
      "           4       0.70      0.73      0.71       107\n",
      "           5       0.54      0.46      0.50        87\n",
      "           6       0.74      0.83      0.78       104\n",
      "           7       0.78      0.79      0.78        89\n",
      "           8       0.65      0.59      0.62       102\n",
      "           9       0.93      0.93      0.93       115\n",
      "          10       0.66      0.66      0.66        98\n",
      "          11       0.74      0.89      0.81       100\n",
      "          12       0.61      0.56      0.59        82\n",
      "\n",
      "    accuracy                           0.75      1300\n",
      "   macro avg       0.73      0.74      0.73      1300\n",
      "weighted avg       0.73      0.75      0.73      1300\n",
      "\n",
      "Training Kernel: rbf\n",
      "Train Accuracy: 0.718974358974359\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.16      0.25       891\n",
      "           1       0.51      0.94      0.67       900\n",
      "           2       0.79      0.87      0.83       895\n",
      "           3       0.98      1.00      0.99       898\n",
      "           4       0.65      0.58      0.61       893\n",
      "           5       0.61      0.54      0.57       913\n",
      "           6       0.65      0.70      0.67       896\n",
      "           7       0.86      0.75      0.80       911\n",
      "           8       0.58      0.62      0.60       898\n",
      "           9       0.89      0.90      0.89       885\n",
      "          10       0.72      0.75      0.73       902\n",
      "          11       0.80      0.75      0.77       900\n",
      "          12       0.85      0.78      0.81       918\n",
      "\n",
      "    accuracy                           0.72     11700\n",
      "   macro avg       0.72      0.72      0.71     11700\n",
      "weighted avg       0.72      0.72      0.71     11700\n",
      "\n",
      "Test Accuracy: 0.7207692307692307\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.21      0.31       109\n",
      "           1       0.54      0.94      0.69       100\n",
      "           2       0.82      0.90      0.85       105\n",
      "           3       1.00      1.00      1.00       102\n",
      "           4       0.74      0.58      0.65       107\n",
      "           5       0.55      0.59      0.57        87\n",
      "           6       0.64      0.73      0.68       104\n",
      "           7       0.78      0.75      0.77        89\n",
      "           8       0.66      0.60      0.63       102\n",
      "           9       0.90      0.89      0.89       115\n",
      "          10       0.67      0.68      0.68        98\n",
      "          11       0.79      0.76      0.78       100\n",
      "          12       0.70      0.76      0.73        82\n",
      "\n",
      "    accuracy                           0.72      1300\n",
      "   macro avg       0.72      0.72      0.71      1300\n",
      "weighted avg       0.73      0.72      0.71      1300\n",
      "\n",
      "Training polynomial degree 3\n",
      "Train Accuracy: 0.718974358974359\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.16      0.25       891\n",
      "           1       0.51      0.94      0.67       900\n",
      "           2       0.79      0.87      0.83       895\n",
      "           3       0.98      1.00      0.99       898\n",
      "           4       0.65      0.58      0.61       893\n",
      "           5       0.61      0.54      0.57       913\n",
      "           6       0.65      0.70      0.67       896\n",
      "           7       0.86      0.75      0.80       911\n",
      "           8       0.58      0.62      0.60       898\n",
      "           9       0.89      0.90      0.89       885\n",
      "          10       0.72      0.75      0.73       902\n",
      "          11       0.80      0.75      0.77       900\n",
      "          12       0.85      0.78      0.81       918\n",
      "\n",
      "    accuracy                           0.72     11700\n",
      "   macro avg       0.72      0.72      0.71     11700\n",
      "weighted avg       0.72      0.72      0.71     11700\n",
      "\n",
      "Test Accuracy: 0.7207692307692307\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.21      0.31       109\n",
      "           1       0.54      0.94      0.69       100\n",
      "           2       0.82      0.90      0.85       105\n",
      "           3       1.00      1.00      1.00       102\n",
      "           4       0.74      0.58      0.65       107\n",
      "           5       0.55      0.59      0.57        87\n",
      "           6       0.64      0.73      0.68       104\n",
      "           7       0.78      0.75      0.77        89\n",
      "           8       0.66      0.60      0.63       102\n",
      "           9       0.90      0.89      0.89       115\n",
      "          10       0.67      0.68      0.68        98\n",
      "          11       0.79      0.76      0.78       100\n",
      "          12       0.70      0.76      0.73        82\n",
      "\n",
      "    accuracy                           0.72      1300\n",
      "   macro avg       0.72      0.72      0.71      1300\n",
      "weighted avg       0.73      0.72      0.71      1300\n",
      "\n",
      "Training polynomial degree 4\n",
      "Train Accuracy: 0.718974358974359\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.16      0.25       891\n",
      "           1       0.51      0.94      0.67       900\n",
      "           2       0.79      0.87      0.83       895\n",
      "           3       0.98      1.00      0.99       898\n",
      "           4       0.65      0.58      0.61       893\n",
      "           5       0.61      0.54      0.57       913\n",
      "           6       0.65      0.70      0.67       896\n",
      "           7       0.86      0.75      0.80       911\n",
      "           8       0.58      0.62      0.60       898\n",
      "           9       0.89      0.90      0.89       885\n",
      "          10       0.72      0.75      0.73       902\n",
      "          11       0.80      0.75      0.77       900\n",
      "          12       0.85      0.78      0.81       918\n",
      "\n",
      "    accuracy                           0.72     11700\n",
      "   macro avg       0.72      0.72      0.71     11700\n",
      "weighted avg       0.72      0.72      0.71     11700\n",
      "\n",
      "Test Accuracy: 0.7207692307692307\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.21      0.31       109\n",
      "           1       0.54      0.94      0.69       100\n",
      "           2       0.82      0.90      0.85       105\n",
      "           3       1.00      1.00      1.00       102\n",
      "           4       0.74      0.58      0.65       107\n",
      "           5       0.55      0.59      0.57        87\n",
      "           6       0.64      0.73      0.68       104\n",
      "           7       0.78      0.75      0.77        89\n",
      "           8       0.66      0.60      0.63       102\n",
      "           9       0.90      0.89      0.89       115\n",
      "          10       0.67      0.68      0.68        98\n",
      "          11       0.79      0.76      0.78       100\n",
      "          12       0.70      0.76      0.73        82\n",
      "\n",
      "    accuracy                           0.72      1300\n",
      "   macro avg       0.72      0.72      0.71      1300\n",
      "weighted avg       0.73      0.72      0.71      1300\n",
      "\n",
      "Training polynomial degree 5\n",
      "Train Accuracy: 0.718974358974359\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.16      0.25       891\n",
      "           1       0.51      0.94      0.67       900\n",
      "           2       0.79      0.87      0.83       895\n",
      "           3       0.98      1.00      0.99       898\n",
      "           4       0.65      0.58      0.61       893\n",
      "           5       0.61      0.54      0.57       913\n",
      "           6       0.65      0.70      0.67       896\n",
      "           7       0.86      0.75      0.80       911\n",
      "           8       0.58      0.62      0.60       898\n",
      "           9       0.89      0.90      0.89       885\n",
      "          10       0.72      0.75      0.73       902\n",
      "          11       0.80      0.75      0.77       900\n",
      "          12       0.85      0.78      0.81       918\n",
      "\n",
      "    accuracy                           0.72     11700\n",
      "   macro avg       0.72      0.72      0.71     11700\n",
      "weighted avg       0.72      0.72      0.71     11700\n",
      "\n",
      "Test Accuracy: 0.7207692307692307\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.21      0.31       109\n",
      "           1       0.54      0.94      0.69       100\n",
      "           2       0.82      0.90      0.85       105\n",
      "           3       1.00      1.00      1.00       102\n",
      "           4       0.74      0.58      0.65       107\n",
      "           5       0.55      0.59      0.57        87\n",
      "           6       0.64      0.73      0.68       104\n",
      "           7       0.78      0.75      0.77        89\n",
      "           8       0.66      0.60      0.63       102\n",
      "           9       0.90      0.89      0.89       115\n",
      "          10       0.67      0.68      0.68        98\n",
      "          11       0.79      0.76      0.78       100\n",
      "          12       0.70      0.76      0.73        82\n",
      "\n",
      "    accuracy                           0.72      1300\n",
      "   macro avg       0.72      0.72      0.71      1300\n",
      "weighted avg       0.73      0.72      0.71      1300\n",
      "\n",
      "Training polynomial degree 6\n",
      "Train Accuracy: 0.718974358974359\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.16      0.25       891\n",
      "           1       0.51      0.94      0.67       900\n",
      "           2       0.79      0.87      0.83       895\n",
      "           3       0.98      1.00      0.99       898\n",
      "           4       0.65      0.58      0.61       893\n",
      "           5       0.61      0.54      0.57       913\n",
      "           6       0.65      0.70      0.67       896\n",
      "           7       0.86      0.75      0.80       911\n",
      "           8       0.58      0.62      0.60       898\n",
      "           9       0.89      0.90      0.89       885\n",
      "          10       0.72      0.75      0.73       902\n",
      "          11       0.80      0.75      0.77       900\n",
      "          12       0.85      0.78      0.81       918\n",
      "\n",
      "    accuracy                           0.72     11700\n",
      "   macro avg       0.72      0.72      0.71     11700\n",
      "weighted avg       0.72      0.72      0.71     11700\n",
      "\n",
      "Test Accuracy: 0.7207692307692307\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.21      0.31       109\n",
      "           1       0.54      0.94      0.69       100\n",
      "           2       0.82      0.90      0.85       105\n",
      "           3       1.00      1.00      1.00       102\n",
      "           4       0.74      0.58      0.65       107\n",
      "           5       0.55      0.59      0.57        87\n",
      "           6       0.64      0.73      0.68       104\n",
      "           7       0.78      0.75      0.77        89\n",
      "           8       0.66      0.60      0.63       102\n",
      "           9       0.90      0.89      0.89       115\n",
      "          10       0.67      0.68      0.68        98\n",
      "          11       0.79      0.76      0.78       100\n",
      "          12       0.70      0.76      0.73        82\n",
      "\n",
      "    accuracy                           0.72      1300\n",
      "   macro avg       0.72      0.72      0.71      1300\n",
      "weighted avg       0.73      0.72      0.71      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "kernels = ['linear', 'rbf']\n",
    "svm_models = {}\n",
    "for kernel in kernels:\n",
    "    print(\"Training Kernel: \" + kernel)\n",
    "    svm_models[kernel] = SVC(kernel=kernel)\n",
    "    svm_models[kernel].fit(X_train, y_train)\n",
    "\n",
    "    GenerateReport(svm_models[kernel], X_train, X_test, y_train, y_test)\n",
    "    \n",
    "for degree in range(3, 7):\n",
    "    print(\"Training polynomial degree \" + str(degree))\n",
    "    key = 'poly-' + str(degree)\n",
    "    svm_models[key] = SVC(kernel=kernel, degree=degree)\n",
    "    svm_models[key].fit(X_train, y_train)\n",
    "\n",
    "    GenerateReport(svm_models[key], X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d5cad6e-5dc9-4689-82fa-ac7946661554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490649     7\n",
       "456695     1\n",
       "354807     0\n",
       "814547     7\n",
       "340245     8\n",
       "          ..\n",
       "280179     0\n",
       "88893     10\n",
       "793675     3\n",
       "824702     9\n",
       "267114    11\n",
       "Name: Activity, Length: 13000, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c77236e-43ca-4e7c-8889-2ff60fee4bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
